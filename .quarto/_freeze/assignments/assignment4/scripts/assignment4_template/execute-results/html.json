{
  "hash": "c7ad1201e73b679487397e7125d4a3b1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 4: Predictive Policing\"\nsubtitle: \"MUSA 5080 - Fall 2025\"\nauthor: \"Itsnatani Anaqami\"\ndate: 03 November 2025\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n## About This Exercise\n\nIn this exercise, I build a spatial predictive model for burglaries using count regression and spatial features.\n\n# Learning Objectives\n\nBy the end of this exercise, I am able to:\n\n1.  Create a fishnet grid for aggregating point-level crime data\n2.  Calculate spatial features including k-nearest neighbors and distance measures\n3.  Diagnose spatial autocorrelation using Local Moran's I\n4.  Fit and interpret Poisson and Negative Binomial regression for count data\n5.  Implement spatial cross-validation (Leave-One-Group-Out)\n6.  Compare model predictions to a Kernel Density Estimation baseline\n7.  Evaluate model performance using appropriate metrics\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Working directory: C:/NATAN/PENN/2025 FALL/Public Policy Analytics/portfolio-setup-itsnatani-humaira/assignments/assignment4/scripts \n```\n\n\n:::\n:::\n\n\n# Part 1: Load and Explore Data\n\nIn this step, I loaded the data I needed for my analysis. The primary data needed was error crime data, as that's what I wanted to predict in this assignment. I also used spatial data such as police districts and beats, as well as Chicago boundaries as a spatial base in mapping the number of crimes. In this step, I also visualized the error data to see crime point locations and observe existing spatial patterns.\n\n## Exercise 1.1: Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 25 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 277 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `chicagoBoundary' from data source \n  `https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.8367 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Coordinate Reference System\n\nI am using `ESRI:102271` (Illinois State Plane East, NAD83, US Feet). This is appropriate for Chicago because:\n\n-   It minimizes distortion in this region\n-   Uses feet (common in US planning)\n-   Allows accurate distance calculations\n:::\n\n## Exercise 1.2: Load Burglary Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"assignments/assignment4/scripts/data\", \"burglaries.shp\")) %>% \n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `burglaries' from data source \n  `C:\\NATAN\\PENN\\2025 FALL\\Public Policy Analytics\\portfolio-setup-itsnatani-humaira\\assignments\\assignment4\\scripts\\data\\burglaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7482 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 340492 ymin: 552959.6 xmax: 367153.5 ymax: 594815.1\nProjected CRS: NAD83(HARN) / Illinois East\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(burglaries$Date, na.rm = TRUE), \"to\", \n    max(burglaries$Date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: 17167 to 17532 \n```\n\n\n:::\n:::\n\n\n**Question 1.1:** How many burglaries are in the dataset? What time period does this cover? Why does the coordinate reference system matter for our spatial analysis? There are 7482 burglaries case in the dataset. The dataset covers data from 2017-01-01 to 2018-01-01. Unifying the The CRS matters because it ensures that all spatial data layers line up correctly and that distance, area, and spatial relationships are measured accurately. Without a consistent and appropriate CRS, the crime points, police districts, and boundaries may misalign, and any calculations (like density or spatial models) would be distorted or wrong.\n\n::: callout-warning\n## Critical Pause #1: Data Provenance\n\nBefore proceeding, consider where this data came from:\n\n**Who recorded this data?** Chicago Police Department officers and detectives\n\n**What might be missing?**\n\n-   Unreported burglaries (victims didn't call police)\n-   Incidents police chose not to record\n-   Downgraded offenses (burglary recorded as trespassing)\n-   Spatial bias (more patrol = more recorded crime)\n\n**Think About** Was there a Department of Justice investigation of CPD during this period? What did they find about data practices? The United States Department of Justice (DOJ) conducted a “pattern or practice” investigation of the Chicago Police Department (CPD) started on December 2015. The findings were announced on January 2017. The report found that CPD “does not effectively document and meaningfully review officers’ use of force”. If CPD’s data collection, management, or transparency was flawed around that period, then data I am using might share systemic limitations (e.g., missing cases, mis-classification, bias). The DOJ’s focus on “documentation and review” suggests that not all force or misconduct events were reliably reported or investigated, which raises caution about relying solely on official incident datasets without considering possible under-reporting or bias.\n:::\n\n## Exercise 1.3: Visualize Point Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(burglaries)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-points-1.png){width=960}\n:::\n:::\n\n\n**Question 1.2:** What spatial patterns do you observe? Are burglaries evenly distributed across Chicago? Where are the highest concentrations? What might explain these patterns?\n\nBurglaries are not evenly distributed across Chicago. There is a clear clustered spatial pattern of burglaries rather than a random distribution.There are areas located in the southern and northern part of the city that have noticeably higher densities than the rest of the city. Peripheral areas show far fewer incidents, which may indicates that burglaries occur often in area with major residential zones, commercial corridors, or transportation routes, rather than peripheral areas.\n\n# Part 2: Create Fishnet Grid\n\nIn this step, I create a 500 × 500 meter fishnet grid, which produces 2,458 cells across Chicago. I then aggregate the burglary incidents into these grid cells using a spatial join, resulting in a consistent unit of analysis for modeling and visualization.\n\n## Exercise 2.1: Understanding the Fishnet\n\nA **fishnet grid** converts irregular point data into a regular grid of cells where we can:\n\n-   Aggregate counts\n-   Calculate spatial features\n-   Apply regression models\n\nThink of it as overlaying graph paper on a map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n**Question 2.1:** Why do we use a regular grid instead of existing boundaries like neighborhoods or census tracts? What are the advantages and disadvantages of this approach? A regular grid gives uniform, equally sized units that avoid the arbitrary shapes of neighborhoods or census tracts. This improves comparability, reduces boundary-related bias (MAUP), and works better for spatial modeling. But there's a limitation too in using grid, the downside is that grids are less intuitive, may split meaningful areas, and can produce many empty cells at fine resolutions.\n\n## Exercise 2.2: Aggregate Burglaries to Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Burglaries\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Burglary Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-fishnet-1.png){width=768}\n:::\n:::\n\n\n**Question 2.2:** What is the distribution of burglary counts across cells? Why do so many cells have zero burglaries? Is this distribution suitable for count regression? (Hint: look up overdispersion)\n\nCompared to the spatial distribution density surface map, the grid map shows more precisely where burglaries occur because it uses uniform cells rather than smoothing the data. The mid-range burglary counts (5–10) appear more evenly distributed across space for the same reason. Many cells have zero burglaries because a 500×500 m grid creates many small units where no incidents fall. This leads to overdispersion (variance greater than the mean), meaning the distribution is not well suited to a basic Poisson regression model.\n\n# Part 3: Create a Kernel Density Baseline\n\nBefore building complex models, let's create a simple baseline using **Kernel Density Estimation (KDE)**.\n\n**The KDE baseline asks:** \"What if crime just happens where it happened before?\" (simple spatial smoothing, no predictors)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-kde-1.png){width=768}\n:::\n:::\n\n\n**Question 3.1:** How does the KDE map compare to the count map? What does KDE capture well? What does it miss?\n\nKDE map smooths point locations and highlights general hotspots, making broad spatial patterns easy to see. It reduces noise by blending nearby incidents, so major clusters stand out clearly. But KDE map does not show exact counts or how many crimes occurred in a specific location. It can blur sharp boundaries and make hotspots look larger or smoother than they really are. On the other hand, the grid count map shows precise spatial detail, showing which cells had 0, 1, or 20 burglaries. It also exposes fine-scale variation that KDE smooths away.\n\n# Part 4: Create Spatial Predictor Variables\n\nNow we'll create features that might help predict burglaries. We'll use \"broken windows theory\" logic: signs of disorder predict crime. In this section, I use vacant and abandoned houses as a predictor of burglary risk. My hypothesis: areas with more vacant or abandoned buildings will have higher burglary counts. These locations often have fewer residents or “eyes on the street,” creating opportunities for offenders. Vacant properties can also signal broader social or economic decline, which may further increase vulnerability to crime.\n\n## Exercise 4.1: Load 311 Vacant and Abandoned House Calls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabandoned_house <- read_csv(here(\"assignments/assignment4/scripts/data/vacant_buildings_2018.csv\"))%>%\n  filter(!is.na(LATITUDE), !is.na(LONGITUDE)) %>%\n  st_as_sf(coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded abandoned house calls\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded abandoned house calls\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of calls:\", nrow(abandoned_house), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of calls: 65073 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Data Loading Note\n\n**Consider:** How might the 311 reporting system itself be biased? Who calls 311? What neighborhoods have better 311 awareness?\n\nThe 311 reporting system can be biased because it reflects who chooses and is able to report problems, not just where problems actually occur. People with more time, resources, or trust in city services are more likely to call. This means affluent neighborhoods often show higher 311 reporting rates, not necessarily because they have more issues, but because residents have greater awareness, access, and expectations for city responsiveness. In contrast, residents in lower-income areas may be used to chronic problems, may not expect the city to respond, or may face barriers such as limited time, internet access, or language support. As a result, 311 data can underrepresent disorder in disadvantaged neighborhoods.\n:::\n\n## Exercise 4.2: Count of Abandoned Houses per Cell\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate abandoned house calls to fishnet\nabandoned_fishnet <- st_join(abandoned_house, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(abandoned_house = n())\n\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(abandoned_fishnet, by = \"uniqueID\") %>%\n  mutate(abandoned_house = replace_na(abandoned_house, 0))\n\ncat(\"Abandoned house distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAbandoned house distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_house)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    1.00    7.00   26.47   28.00  378.00 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abandoned_house), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"magma\") +\n  labs(title = \"Abandoned House 311 Calls\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\") +\n  labs(title = \"Burglaries\") +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(title = \"Are abandoned houses and burglaries correlated?\")\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-abandoned-houses-1.png){width=960}\n:::\n:::\n\n\n**Question 4.1:** Do you see a visual relationship between abandoned houses and burglaries? What does this suggest?\n\nVisually, the relationship is not extremely strong, but two of the hotspots of abandoned-house reports, which located in the southeast and southern areas, do overlap with higher burglary counts. This indicates that vacancy may contribute to elevated burglary risk in certain neighborhoods, even if it does not explain the overall citywide pattern.\n\n## Exercise 4.3: Nearest Neighbor Features\n\nCount in a cell is one measure. Distance to the nearest 3 abandoned houses captures local context.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest abandoned houses\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nabandoned_coords <- st_coordinates(abandoned_house)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(abandoned_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    abandoned_house.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_house.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n   0.8904   78.5326  154.3596  261.9420  313.4905 1997.1334 \n```\n\n\n:::\n:::\n\n\n**Question 4.2:** What does a low value of `abandoned_house.nn` mean? A high value? Why might this be informative?\n\nLow values means the cell is very close to an abandoned house. Possibly adjacent or within a short walking distanceand indicates local concentration or clustering of abandoned houses. On the other hand, high values means the cell is far away from any abandoned house. Indicates areas with few or no abandoned properties nearby and suggests spatial separation from problem properties. Many outcomes (crime, property values, blight spread) depend not just on whether abandoned houses exist, but how close they are. Distance gives nuance beyond a binary yes/no.\n\n## Exercise 4.4: Distance to Hot Spots\n\nLet's identify clusters of abandoned houses using Local Moran's I, then calculate distance to these hot spots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to abandoned houses\nfishnet <- calculate_local_morans(fishnet, \"abandoned_house\", k = 5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Abandoned House Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/visualize-morans-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to abandoned houses hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to abandoned houses hot spots\n  - Number of hot spot cells: 294 \n```\n\n\n:::\n:::\n\n\n**Question 4.3:** Why might distance to a cluster of abandoned houses be more informative than distance to a single abandoned house? What does Local Moran's I tell us?\n\nDistance to a cluster of abandoned houses is more informative than distance to a single abandoned house because clusters reflect real, neighborhood-level decline, while one vacant property may be an isolated or temporary issue. Local Moran’s I helps identify these meaningful patterns by showing where high values group together (hotspots) or where low values group together (stable areas), allowing us to distinguish true problem areas from random outliers.\n\n::: callout-note\n**Local Moran's I** identifies:\n\n-   **High-High**: Hot spots (high values surrounded by high values)\n-   **Low-Low**: Cold spots (low values surrounded by low values)\n-   **High-Low / Low-High**: Spatial outliers\n:::\n\n------------------------------------------------------------------------\n\n# Part 5: Join Police Districts for Cross-Validation\n\nIn this part, I attach police district information to each fishnet cell. I join the fishnet grid with the police district boundaries so that every cell is labeled with the district it falls into. This step is necessary because later on, I will use these district labels to perform spatial cross-validation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n:::\n\n\n# Part 6: Model Fitting\n\nIn this step, I prepared a clean modeling dataset from the fishnet grid and fit statistical models to explain burglary counts. I first used a Poisson regression, which is the standard approach for modeling count data like crime incidents. Then, because Poisson models assume the mean and variance are equal, I checked for overdispersion—a common issue in real crime data where variance is much larger than the mean. Detecting overdispersion is essential because it can lead to biased estimates and misleading significance levels. When overdispersion was detected, I fit a Negative Binomial regression, which relaxes this assumption and provides more reliable estimates. Comparing AIC values allowed me to choose the model that best fits the data. Overall, this step ensures that the final crime prediction model is statistically sound, interpretable, and appropriate for the structure of the data.\n\n## Exercise 6.1: Poisson Regression\n\nBurglary counts are count data (0, 1, 2, 3...). I'll use **Poisson regression**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    abandoned_house,\n    abandoned_house.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 6 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ abandoned_house + abandoned_house.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ abandoned_house + abandoned_house.nn + \n    dist_to_hotspot, family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                       Estimate   Std. Error z value             Pr(>|z|)    \n(Intercept)         1.889753745  0.032485489  58.172 < 0.0000000000000002 ***\nabandoned_house     0.001998030  0.000239185   8.354 < 0.0000000000000002 ***\nabandoned_house.nn -0.004631984  0.000178454 -25.956 < 0.0000000000000002 ***\ndist_to_hotspot    -0.000030309  0.000005665  -5.351         0.0000000876 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6710.3  on 1707  degrees of freedom\nResidual deviance: 4256.4  on 1704  degrees of freedom\nAIC: 8324.7\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n**Question 6.1:** Interpret the coefficients. Which variables are significant? What do the signs (positive/negative) tell you?\n\nAll three predictors are statistically significant at the p < 0.001 level, which means each variables has a meaningful relationship with burglary counts in the fishnet grid.Positive sign means the burglary risk increases as the number of variable increases, and the negative sign tells the opposite, where burglary risk decreases as the number of variable increases.\n- abandoned_house (positive, significant):\nMore abandoned houses within the cell are associated with higher burglary counts.\n- abandoned_house.nn (negative, significant):\nHigher abandoned-house levels in neighboring cells are associated with lower burglaries in this cell. This may seem counterintuitive, but this variable is the neighbor average, not the local count. A negative coefficient suggests burglaries cluster away from areas with very high neighboring abandonment.\n\nOften, extremely distressed surrounding areas may have: Fewer targets, lower residential density, less foot traffic, and fewer occupied homes to burglarize. So this variable picks up spillover effects, not local opportunity.\n- dist_to_hotspot (negative, significant):\nCells closer to abandonment hotspots experience more burglaries; burglary risk decreases as distance increases.\n\n\n## Exercise 6.2: Check for Overdispersion\n\nPoisson regression assumes mean = variance. Real count data often violates this (overdispersion).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 2.76 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\n\n## Exercise 6.3: Negative Binomial Regression\n\nIf overdispersed, use **Negative Binomial regression** (more flexible).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ abandoned_house + abandoned_house.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ abandoned_house + abandoned_house.nn + \n    dist_to_hotspot, data = fishnet_model, init.theta = 2.148065219, \n    link = log)\n\nCoefficients:\n                       Estimate   Std. Error z value             Pr(>|z|)    \n(Intercept)         1.935501113  0.056376458   34.33 < 0.0000000000000002 ***\nabandoned_house     0.001999655  0.000487666    4.10            0.0000412 ***\nabandoned_house.nn -0.005266039  0.000256987  -20.49 < 0.0000000000000002 ***\ndist_to_hotspot    -0.000018583  0.000008768   -2.12                0.034 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.1481) family taken to be 1)\n\n    Null deviance: 2936.4  on 1707  degrees of freedom\nResidual deviance: 1812.3  on 1704  degrees of freedom\nAIC: 7271.4\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.148 \n          Std. Err.:  0.135 \n\n 2 x log-likelihood:  -7261.384 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 8324.7 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7271.4 \n```\n\n\n:::\n:::\n\n\n**Question 6.2:** Which model fits better (lower AIC)? What does this tell you about the data?\n\nThe Negative Binomial model fits better, because it has a lower AIC (7271.4 vs. 8324.7). This tells us that the burglary data are **overdispersed**—the variance is larger than what the Poisson model can handle—so a Negative Binomial model provides a more accurate and appropriate fit for these crime counts.\n\n*Your answer here:*\n\n# Part 7: Spatial Cross-Validation\n\nStandard cross-validation randomly splits data. But with spatial data, this means training on cells right next to test cells (information leakage!).\n\nIn this part, I perform spatial cross-validation to evaluate how well the model generalizes across different parts of the city. I use police districts as the spatial units for cross-validation because they represent meaningful, operational geographic boundaries where conditions tend to be internally similar but different from neighboring districts. Using districts reduces spatial leakage—where nearby locations in the training data accidentally help predict the test data—and therefore provides a more realistic assessment of model performance. Police districts also align the analysis with how the city organizes public safety and resource allocation, making the results more interpretable and actionable for policymakers.\n\n**Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ abandoned_house + abandoned_house.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 2.09 \n  Fold 2 / 22 - District 4 - MAE: 1.73 \n  Fold 3 / 22 - District 22 - MAE: 2.31 \n  Fold 4 / 22 - District 6 - MAE: 2.83 \n  Fold 5 / 22 - District 8 - MAE: 2.21 \n  Fold 6 / 22 - District 7 - MAE: 4.01 \n  Fold 7 / 22 - District 3 - MAE: 5.16 \n  Fold 8 / 22 - District 2 - MAE: 2.26 \n  Fold 9 / 22 - District 9 - MAE: 2.24 \n  Fold 10 / 22 - District 10 - MAE: 2.06 \n  Fold 11 / 22 - District 1 - MAE: 1.87 \n  Fold 12 / 22 - District 12 - MAE: 3.27 \n  Fold 13 / 22 - District 15 - MAE: 2.07 \n  Fold 14 / 22 - District 11 - MAE: 3.06 \n  Fold 15 / 22 - District 18 - MAE: 2.31 \n  Fold 16 / 22 - District 25 - MAE: 2.64 \n  Fold 17 / 22 - District 14 - MAE: 2.95 \n  Fold 18 / 22 - District 19 - MAE: 1.92 \n  Fold 19 / 22 - District 16 - MAE: 1.82 \n  Fold 20 / 22 - District 17 - MAE: 1.6 \n  Fold 21 / 22 - District 20 - MAE: 1.43 \n  Fold 22 / 22 - District 24 - MAE: 2.03 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.45 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.36 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>LOGO CV Results by District</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fold </th>\n   <th style=\"text-align:left;\"> test_district </th>\n   <th style=\"text-align:right;\"> n_test </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 5.16 </td>\n   <td style=\"text-align:right;\"> 7.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 52 </td>\n   <td style=\"text-align:right;\"> 4.01 </td>\n   <td style=\"text-align:right;\"> 4.68 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 3.27 </td>\n   <td style=\"text-align:right;\"> 4.81 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 3.06 </td>\n   <td style=\"text-align:right;\"> 3.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 2.95 </td>\n   <td style=\"text-align:right;\"> 4.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.83 </td>\n   <td style=\"text-align:right;\"> 4.02 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 85 </td>\n   <td style=\"text-align:right;\"> 2.64 </td>\n   <td style=\"text-align:right;\"> 3.68 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 22 </td>\n   <td style=\"text-align:right;\"> 112 </td>\n   <td style=\"text-align:right;\"> 2.31 </td>\n   <td style=\"text-align:right;\"> 2.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 2.31 </td>\n   <td style=\"text-align:right;\"> 4.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:right;\"> 3.15 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 2.24 </td>\n   <td style=\"text-align:right;\"> 2.78 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:right;\"> 197 </td>\n   <td style=\"text-align:right;\"> 2.21 </td>\n   <td style=\"text-align:right;\"> 3.21 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n   <td style=\"text-align:right;\"> 2.09 </td>\n   <td style=\"text-align:right;\"> 2.74 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 2.07 </td>\n   <td style=\"text-align:right;\"> 2.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.06 </td>\n   <td style=\"text-align:right;\"> 2.79 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:left;\"> 24 </td>\n   <td style=\"text-align:right;\"> 41 </td>\n   <td style=\"text-align:right;\"> 2.03 </td>\n   <td style=\"text-align:right;\"> 3.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> 19 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 1.92 </td>\n   <td style=\"text-align:right;\"> 2.50 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 1.87 </td>\n   <td style=\"text-align:right;\"> 2.74 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:right;\"> 129 </td>\n   <td style=\"text-align:right;\"> 1.82 </td>\n   <td style=\"text-align:right;\"> 2.26 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 235 </td>\n   <td style=\"text-align:right;\"> 1.73 </td>\n   <td style=\"text-align:right;\"> 3.28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 1.60 </td>\n   <td style=\"text-align:right;\"> 2.11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:left;\"> 20 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 1.43 </td>\n   <td style=\"text-align:right;\"> 1.88 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 7.1:** Why is spatial CV more appropriate than random CV for this problem? Which districts were hardest to predict?\n\nSpatial CV is more appropriate because crime risk is spatially autocorrelated—nearby locations tend to have similar crime patterns.\nIf we use random CV, training and test samples are often neighbors, so the model cheats by learning from areas that are almost identical to the test set. This leads to overly optimistic accuracy.\nUsing police districts for CV forces the model to predict entire unseen geographic areas, reducing spatial leakage and giving a more realistic measure of generalizability—closer to how the model would perform in new districts.\nFrom the result, The hardest districts to predict are those with the highest error values (MAE and RMSE), which are: District 3, District 7, and District 12.\n\n# Part 8: Model Predictions and Comparison\n\n## Exercise 8.1: Generate Final Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ abandoned_house + abandoned_house.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n## Exercise 8.2: Compare Model vs. KDE Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/compare-models-1.png){width=1152}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> approach </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.24 </td>\n   <td style=\"text-align:right;\"> 3.28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.06 </td>\n   <td style=\"text-align:right;\"> 2.95 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 8.1:** Does the complex model outperform the simple KDE baseline? By how much? Is the added complexity worth it?\n\nThe results indicate that the complex regression model does not outperform the simple KDE baseline.\nMAE: KDE is lower by 0.18 (2.06 vs. 2.24)\nRMSE: KDE is lower by 0.33 (2.95 vs. 3.28)\nThe results represents roughly an 8-10% gain in predictive accuracy. While the differences are modest, they are consistent across both metrics.\n\nThese findings suggest that the added complexity of the model does not translate into better predictive performance. Although the complex model may still offer value for interpretation—such as understanding how specific environmental features relate to crime—its predictive accuracy does not exceed that of the simpler KDE method.\n\n## Exercise 9.3: Where Does the Model Work Well?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/prediction-errors-1.png){width=960}\n:::\n:::\n\n\n**Question 9.2:** Where does the model make the biggest errors? Are there spatial patterns in the errors? What might this reveal?\n\nThe absolute error map shows the largest errors in:\n-   The far South Side\n-   The Southeast lakefront\n-   A few pockets in the Southwest\n\nOn the other hand, the model performs better in:\nCentral and North Side neighborhoods, where burglary counts are lower and more stable.\n\nThe errors are not randomly scattered. Errors cluster in specific area.\nThe error pattern may suggest:\n\n1. The model struggles in places with atypical dynamics\nAreas with unusually high crime, high vacancy, or rapid neighborhood change produce the largest errors.\n\n2. 311 data may not reflect true conditions everywhere\nIf certain neighborhoods underreport 311 issues (e.g., low civic engagement, distrust of government), the predictor becomes biased - and the model mispredicts.\n\n3. Burglary is influenced by factors not included in the model, such as:\n-   Socioeconomic conditions\n-   Policing patterns\n-   Land use\n-   Housing density\n-   Opportunity structures (commercial corridors, transit access)\n\n# Part 10: Summary Statistics and Tables\n\n## Exercise 10.1: Model Summary Table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>Final Negative Binomial Model Coefficients (Exponentiated)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Rate Ratio </th>\n   <th style=\"text-align:right;\"> Std. Error </th>\n   <th style=\"text-align:right;\"> Z </th>\n   <th style=\"text-align:right;\"> P-Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 6.928 </td>\n   <td style=\"text-align:right;\"> 0.056 </td>\n   <td style=\"text-align:right;\"> 34.332 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> abandoned_house </td>\n   <td style=\"text-align:right;\"> 1.002 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 4.100 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> abandoned_house.nn </td>\n   <td style=\"text-align:right;\"> 0.995 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -20.491 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dist_to_hotspot </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -2.120 </td>\n   <td style=\"text-align:right;\"> 0.034 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Rate ratios &gt; 1 indicate positive association with burglary counts.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n## Exercise 10.2: Key Findings Summary\n\n**Technical Performance:**\n\n-   Cross-validation MAE: 2.45\n-   Model vs. KDE: \\[The KDE baseline performed slightly better, with lower MAE (2.06 vs. 2.24) and RMSE (2.95 vs. 3.28).\\]\n-   Most predictive variable: \\[abandoned_house.nn (large effect, highly significant).\\]\n\n**Spatial Patterns:**\n\n-   Burglaries are \\[Clustered, not evenly distributed.\\]\n-   Hot spots are located in \\[upper-central and Southeast lakefront neighborhoods\\]\n-   Model errors show \\[systematic\\] patterns\n\n**Model Limitations:**\n\n-   Overdispersion: \\[Poisson model was overdispersed; Negative Binomial provided a better fit (AIC 7271 vs. 8324).\\]\n-   Spatial autocorrelation in residuals: \\[Test this!\\]\n-   Cells with zero counts: \\[781 / 2458 ( 31.8 % of data)\\]\n\n# Conclusion and Next Steps\nThe model identifies significant spatial clustering of burglaries, with clear hotspots in specific neighborhoods. While the model performs better than a simple KDE baseline, some residual spatial autocorrelation remains, indicating localized patterns not fully captured.\n\nNext Steps:\n-   Refine the model by incorporating temporal patterns (time of day, seasonality) and additional environmental factors (street lighting, security presence).\n-   Monitor changes over time to assess model accuracy and effectiveness of interventions.\n-   Explore integrating predictive outputs with city planning tools to inform broader neighborhood safety strategies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---------------------------------------------\n# Part 11: Residual Spatial Autocorrelation\n# ---------------------------------------------\n\n# 1. Calculate residuals from the final Negative Binomial model\nfishnet <- fishnet %>%\n  mutate(\n    residual_nb = countBurglaries - prediction_nb\n  )\n\n# 2. Prepare spatial weights\n# Use k-nearest neighbors (k = 5, as in Local Moran's I earlier)\nlibrary(spdep)\n\n# Get centroid coordinates of fishnet cells\ncoords <- st_coordinates(st_centroid(fishnet))\n\n# Create neighbors using k-nearest neighbors\nknn_neighbors <- knearneigh(coords, k = 5)\nnb_list <- knn2nb(knn_neighbors)\n\n# Convert neighbors to spatial weights list (row-standardized)\nlw <- nb2listw(nb_list, style = \"W\", zero.policy = TRUE)\n\n# 3. Calculate global Moran's I\nmoran_global <- moran.test(fishnet$residual_nb, lw, zero.policy = TRUE)\n\ncat(\"\\nGlobal Moran's I for model residuals:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nGlobal Moran's I for model residuals:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(moran_global)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  fishnet$residual_nb  \nweights: lw    \n\nMoran I statistic standard deviate = 20.057, p-value <\n0.00000000000000022\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.2883249555     -0.0005858231      0.0002074834 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 4. Optional: Local Moran's I to map residual clusters\nlocal_moran_resid <- localmoran(fishnet$residual_nb, lw, zero.policy = TRUE)\n\n# Add Local Moran's I results back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    local_i_resid = local_moran_resid[, 1],\n    p_value_resid = local_moran_resid[, 5],\n    is_significant_resid = p_value_resid < 0.05\n  )\n\n# 5. Visualize significant clusters of residuals\nlibrary(ggplot2)\n\nggplot(fishnet) +\n  geom_sf(aes(fill = ifelse(is_significant_resid, local_i_resid, NA)), color = NA) +\n  scale_fill_gradient2(\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0, na.value = \"gray90\",\n    name = \"Local Moran's I\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Residuals from Negative Binomial Model\",\n    subtitle = \"Red = high residual clusters, Blue = low residual clusters\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n",
    "supporting": [
      "assignment4_template_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}